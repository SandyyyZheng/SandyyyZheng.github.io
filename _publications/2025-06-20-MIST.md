---
title: "MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning"
collection: publications
category: preprints
permalink: /publication/2025-06-20-MIST
excerpt: 'We propose an effective method for jailbreaking black-box LLMs via Iterative Semantic Tuning.'
date: 2025-06-20
venue: 'arXiv Preprint'
paperurl: 'http://sandyyyzheng.github.io/files/MIST_arXiv.pdf'
authors: "**Muyang Zheng**, Yuanzhi Yao<sup>*</sup>, Changting Lin, Rui Wang, Meng Han"
abstract: |
  Despite efforts to align large language models (LLMs) with societal and moral values, these models remain susceptible to jailbreak attacks－methods designed to elicit harmful responses. Jailbreaking black-box LLMs is considered challenging due to the discrete nature of token inputs, restricted access to the target LLM, and limited query budget. To address the issues above, we propose an effective method for jailbreaking black-box large language Models via Iterative Semantic Tuning, named MIST. MIST enables attackers to iteratively refine prompts that preserve the original semantic intent while inducing harmful content. Specifically, to balance semantic similarity with computational efficiency, MIST incorporates two key strategies: sequential synonym search, and its advanced version－order-determining optimization. Extensive experiments across two open-source models and four closed-source models demonstrate that MIST achieves competitive attack success rates and attack transferability compared with other state-of-the-art white-box and black-box jailbreak methods. Additionally, we conduct experiments on computational efficiency to validate the practical viability of MIST.
---
